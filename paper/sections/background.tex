\section{Existence of the "in tension"} \label{sec:outline}
\subsection{\label{sec:level2}Introduction to $H_0$}
Nowadays, the theory that our universe is consistently expanding has been widely accepted. The factor that represents the rate of its expansion was first introduced by Edwin Hubble by stating the fact that galaxies with larger distances from earth move faster away with higher speed, which is now what we call the Hubble Constant $H_0$ (Hubble 1929) \cite{Hubble_1929}. 

 Uncertainties in the physical assumptions used to calculate these distances have resulted in differing Hubble constant estimations. Initially, Hubble’s calculations give roughly $500 km/s/Mpc$ by simply calculating the ratio between velocity and distance(Hubble 1929)\cite{Hubble_1929}. With progressively elaborating the measurement methods, the current $H_0$ value is gradually stabilized at approximately $70 km/s/Mpc$. 

However, different measurement approaches lead to diverse $H_0$ values. The estimated measurement uncertainties have diminished as procedures have improved, but the range of measured values has not, to the point that the disagreement is now exceptionally statistically significant.


\subsection{\label{sec:level2}Measurement inconsistent}
Two dominant approaches give different values, which leads to the data “in tension”. The first method uses low redshift measurements of standard candles (footnote explaining SC), type Ia Supernovae in the measurements for $H_0$. Through this method, $H_0$  $74.03 \pm 1.42 km/s/Mpc$  (Riess et. al. 2019).

Another approach from the high redshift measurements of CMB (cosmic microwave background) gives the newest $H_0$ value about $67.36 \pm 0.56km/s/Mpc$. (Plank 2018). These two measurements give a significant discrepancy, larger than $4 \sigma$, with each other, and such a discrepancy cannot be omitted via statistical explanation.

%\begin{figure}
%    \centering
%    \includegraphics[scale=0.55]{sections/H0whisker.JPG}
%    \caption{History $H_0$ in tension}
%    \label{fig:hist_h0}
%\end{figure}

\subsection{\label{sec:level2}Measurement approaches}

\paragraph{Low redshift ($z \leq 10$) measurement}

The $H_0$ is calculated locally by measuring the redshift of distant galaxies and then using a particular method to calculate their distances which is part of the cosmic distance ladder.
The redshift can be easily measured, and the distances can be measured locally by getting the distance from the standard candle techniques, including the Type Ia Supernovae and Cepheid variables.
 \footnote{Astronomers use a “standard candle” to measure distances that are too vast to be measured using parallax. Because the light is spread out over a larger region, distant light sources appear fainter.}

Tamara et. al gives a statement that even small systematic errors in redshift will result in a significant impact on $H_0$ measurements (2019)\cite{Davis_2019}; however, only considering those errors are not quite enough to resolve the $H_0$ tension people encountered. The research calculation results remain stable with constantly decreasing the error bar, as shown in the figure, except for the results obtained by Freedman et. al. in 2019 shows the relatively low $H_0$ value falls in $69.8 \pm 1.88 km/s/Mpc$\cite{Freedman_2019}. Instead of using Cepheid variables, they use the calibration of Tip of the Red Giant Branch(TRGB), which is parallel to but independent from the former one. TRGB samples have higher mass and less sensitivity to the metallicity, so that the potential systematic error in measurement has decreased.

\paragraph{High redshift ($z \geq 10$) measurement}

$H_0$ can be calculated using CMB temperature changes. Several characteristics, like the ratio of baryonic to dark matter and $H_0$, influence the specific shape of the curve (known as the acoustic power spectrum). The angular diameter distance to the last scattering surface is used to calculate $H_0$. That isn’t a direct observable; instead, trigonometry is used to infer it. The angular scale of the Baryon Acoustic Oscillations in the CMB may be directly measured, it’s the distance between troughs in the power spectrum is shown below.

The temperature power spectrum is what is being used to determine the $H_0$. This is a way of looking at the ripples in the temperature field which encode the amount of dark and baryonic matter present, as well as the cosmological constant and other cosmological parameters.
\footnote{All the parameters are simultaneously constrained with respect to each other using MCMC or other "fitting" approaches. }

There are two possible systematic errors that are commonly seen. When we use two different likelihood pipelines for the data at certain multipoles, with different parameters used for the calibration efficiencies, it has little effect in reducing the Hubble tension (Efstathiou $\&$ Gratton 2021). Therefore, the choice of likelihood will result in systematic errors. 
The second is the systematic error that can occur in the lensing parameter(Calabrese et. al. 2008). The lensing parameter simply rescales by hand the effects of gravitational lensing on the CMB angular power spectra and can be measured by the smoothing of the peaks in the damping tail. This lensing anomaly is not seen in the
Planck trispectrum data \footnote{CMB lensing} that offer a complementary and independent measurement. If there is no new physics in it, the alternative explanation could be due to a small but still undetected systematic error in the Planck data which can be used to reduce the Hubble Tension.

\subsection{\label{Goals} Goals}
In this paper we consider dark siren measurements which do not have a known electromagnetic counterpart. This is relevant for binary black hole hole mergers which are not expected to have observable EM counterparts but occur much more frequently than events with EM counterparts. As of writing, GW170817 is the only event known neutron start merger with an identified EM counterpart \cite{GW170817_announce}.

As early as 1986 it was proposed that an array of multiple gravitational wave detectors could be used to estimate the distance to an event $d_L$ and bounds on sky location\cite{Schutz_1986}. These estimates can then be used to prouce a catalog of candidate host galaxies from existing sky surveys. Based on the posterior distributions for these localizations, we use a method for measuring $H_0$ layed out by Nair et al\cite{Nair_2018}. It has been predicted that these methods can confine the Hubble constant within the decade \cite{Chen_2018}. This technique was applied to the event GW170814 by collaborators from the LIGO and Virgo teams using results from the Dark Energy Survey of the southern sky\cite{GW170814_DES}. We carry out a similar analysis on simulated data sets based on historic GW data and simple physical assumptions for the distribution of galaxies within clusters.



(not sure if we have to include):
Gravitational Lensing also introduced a significant systematic error during measuring the high redshift $z$ (Hilbert et. al. 2018). 
